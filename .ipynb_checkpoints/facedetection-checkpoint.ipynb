{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.5) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:245: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-179b7f5f95bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;31m#numpy행렬을 np.int타입으로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moverlay_transparent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mori\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverlay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverlay_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m#visualize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-179b7f5f95bb>\u001b[0m in \u001b[0;36moverlay_transparent\u001b[1;34m(background_img, img_to_overlay_t, x, y, overlay_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[0mroi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbg_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m   \u001b[0mimg1_bg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m   \u001b[0mimg2_fg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_to_overlay_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_to_overlay_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.5) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\arithm.cpp:245: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2, dlib, sys\n",
    "import numpy as np\n",
    "\n",
    "scaler = 0.3\n",
    "cap = cv2.VideoCapture('girl.mp4')\n",
    "detector = dlib.get_frontal_face_detector()#얼굴 디렉터 모듈 초기화\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "#load video\n",
    "cap = cv2. VideoCapture('girl.mp4')\n",
    "#load overlay image\n",
    "overlay = cv2.imread('face.png', cv2.IMREAD_UNCHANGED)\n",
    "#cv2.imread(file, cv2.IMREAD_NUMCHANGED) -> file이미지를 BGRA타입으로 읽기\n",
    "\n",
    "def overlay_transparent(background_img, img_to_overlay_t, x, y, overlay_size=None):\n",
    "  bg_img = background_img.copy()\n",
    "  # convert 3 channels to 4 channels\n",
    "  if bg_img.shape[2] == 3:\n",
    "    bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "  if overlay_size is not None:\n",
    "    img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "\n",
    "  b, g, r, a = cv2.split(img_to_overlay_t)\n",
    "\n",
    "  mask = cv2.medianBlur(a, 5)\n",
    "\n",
    "  h, w, _ = img_to_overlay_t.shape\n",
    "  roi = bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)]\n",
    "\n",
    "  img1_bg = cv2.bitwise_and(roi.copy(), roi.copy(), mask=cv2.bitwise_not(mask))\n",
    "  img2_fg = cv2.bitwise_and(img_to_overlay_t, img_to_overlay_t, mask=mask)\n",
    "\n",
    "  bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)] = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "  # convert 4 channels to 4 channels\n",
    "  bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "  return bg_img\n",
    "\n",
    "face_roi = []\n",
    "face_sizes = []\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret,img = cap.read()\n",
    "    if not ret:\n",
    "        break;\n",
    "        \n",
    "    img = cv2.resize(img, (int(img.shape[1] * scaler), int(img.shape[0] * scaler)))#동영상 사이즈 너무 커서 resize\n",
    "    ori = img.copy()\n",
    "    \n",
    "    #detect faces\n",
    "    faces = detector(img)\n",
    "    face = faces[0]\n",
    "    \n",
    "    dlib_shape = predictor(img,face) #img의 face영역 안의 얼굴 특징점 찾기\n",
    "    shape_2d = np.array([[p.x,p.y] for p in dlib_shape.parts()]) #연산 쉽게하기 위함\n",
    "    \n",
    "    #compute center and boundaries of face \n",
    "    #특징점찾은 이유 : 얼굴의 좌상단, 우하단, 얼굴의 사이즈, 중심 구하기\n",
    "    top_left = np.min(shape_2d, axis=0)\n",
    "    bottom_right = np.max(shape_2d, axis=0)\n",
    "   \n",
    "    #우하단에서 좌상단 좌표를 뺀 (x,y 길이의 가장 긴 값)\n",
    "    face_size = int(max(bottom_right - top_left)*2.5)\n",
    "    \n",
    "    \n",
    "    #모든 특징점의 평균 구해서 얼굴 중앙 찾기 : np.mean()\n",
    "    center_x, center_y = np.mean(shape_2d,axis=0).astype(np.int)\n",
    "    #소수점일수도 있어서 int형으로 변경 : np.astype(np.int) \n",
    "    #numpy행렬을 np.int타입으로 변환\n",
    "   \n",
    "    result = overlay_transparent(ori, overlay, center_x, center_y, overlay_size=(face_size, face_size))\n",
    "    \n",
    "    #visualize\n",
    "    img = cv2.rectangle(img, pt1=(face.left(), face.top()), pt2=(face.right(), face.bottom()), color=(255,255,255),thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    for s in shape_2d: #얼굴 특징점 68개\n",
    "        cv2.circle(img, center=tuple(s), radius=1, color=(255,255,255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    #특징점으로 만든 얼굴의 사이즈 -> 원그리기\n",
    "    cv2.circle(img, center=tuple(top_left), radius=1, color=(255,0,0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, center=tuple(bottom_right), radius=1, color=(255,0,0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, center=tuple((center_x, center_y)), radius=1, color=(0,0, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('result', result)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
